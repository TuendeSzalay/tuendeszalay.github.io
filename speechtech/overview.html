---
layout: default
---
<body>
<p> I have worked on two speech corpora, AusKidTalk and the Future Proofing study corpus. </p>
  AusKidTalk aims to create an annotated acoustic corpus of Australian childrenâ€™s speech, sufficiently larger for developing automatic speech recognition systems for children. 
  I work on developing semi-automatic workflows for annotating the acoustic data. For more details, see the <a href="http://www.auskidtalk.edu.au/"> AusKidTalk website</a>. </p>
<p>  
  The Future Proofing Study aims to prevent depression and anxiety in Australian adolescents using big data, collecting detailed demographic- and mental health surveys as well as speech samples. 
  I work on phonetic analysis of the resulting corpus. For more details, see the <a href="https://www.blackdoginstitute.org.au/research-centres/future-proofing/"> Future Proofing Study website</a>. </p>

<h2> Publications related to these projects: </h2>
<p>Szalay, T., Shahin, M., Sirojan, T., Nan, Z., Huang, R., Ballard, K., Ahmed, B. (2025) AusKidTalk: Using Strategic Data Collection and Out-of-Domain Tools to Semi-Automate Novel Corpora Annotation. <i>Proceedings of Interspeech 2025</i>, 4268-4272, <a href="https://doi.org/10.21437/interspeech.2025-539">DOI</a> :: <a href="Szalay_etal2025_AusKidTalk_automatic_INTERSPEECH.pdf">PDF</a> :: <a href="Szalay2025_AusKidTalk_automatic_INTERSPEECH.bib">BIB</p> 
  
<p>Zhang, X., Liu, D., Xiao, T., Xiao, C., Szalay, T., Shahin, M., Ahmed, B., Epps, J. (2025) Auto-Landmark: Acoustic Landmark Dataset and Open-Source Toolkit for Landmark Extraction. <i>Proceedings of Interspeech 2025</i>, 4263-4267. <a href="https://doi.org/10.21437/interspeech.2025-17">DOI</a> :: <a href="Zhang_etal2025_autolandmark_INTERSPEECH.pdf">PDF</a> :: <a href="Zhang2025_autolandmark_INTERSPEECH.bib">BIB<a/ </p>  
  
<p>Szalay, T., Stasak, B., Maston, K., Werner-Seidler, A., & Larsen, M. (2024). Exploring fundamental frequency characteristics of Australian adolescents with and without depression in The Future Proofing Study Corpus. In <i>Proceedings of the 19th Australasian International Conference on Speech Science and Technology,</i> (pp. 262-266). <a href="Szalay_etal2024_F0_depression_SST.pdf">PDF</a> </p>
  
<p>Szalay, T., Ratko, L., Shahin, M., Sirojan, T., Ballard, K., Cox, F., & Ahmed, B. (2022). A semi-automatic workflow for orthographic transcription of a novel speech corpus: A case study of AusKidTalk. In Rosey Billington (Ed.) <i>Proceedings of the 18th Australasian International Conference on Speech Science and Technology,</i> (pp. 126-130). <a href="Szalay_etal2022_workflow_SST.pdf">PDF</a> :: <a href="Szalay2022workflow.bib">BIB</a></p>
  
<p> Szalay, T., Shahin, M., Ahmed, B., & Ballard, K. (2022). Training forced aligners on (mis)matched data: The effect of dialect and age. In Rosey Billington (Ed.) <i>Proceedings of the 18th Australasian International Conference on Speech Science and Technology,</i> (pp. 36-40). <a href="Szalay_etal2022_training_SST.pdf">PDF </a> :: <a href="Szalay2022training.bib">BIB</a> </p>
  
<p> Szalay, T., Shahin, M., Ahmed, B., & Ballard, K. (2022). Knowledge of accent differences can be used to predict speech recognition. <i> Proceedings of the 23rd INTERSPEECH Conference</i>. <a href="Szalay_etal2022_knowledge_Interspeech.pdf"> PDF </a> :: <a href="Szalay2022knowledge.bib">BIB</a> :: <a href="10.21437/Interspeech.2022-10162">DOI</a></p>
